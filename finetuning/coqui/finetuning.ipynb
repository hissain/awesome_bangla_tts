{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0bde22f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0bde22f",
        "outputId": "2b3f115c-5ec8-460a-bc22-ca1f1009a4e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.24.3 in /usr/local/lib/python3.11/dist-packages (1.24.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: tts in /usr/local/lib/python3.11/dist-packages (0.22.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: cython>=0.29.30 in /usr/local/lib/python3.11/dist-packages (from tts) (3.0.12)\n",
            "Requirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from tts) (1.14.1)\n",
            "Requirement already satisfied: torch>=2.1 in /usr/local/lib/python3.11/dist-packages (from tts) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from tts) (2.6.0+cu124)\n",
            "Requirement already satisfied: soundfile>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from tts) (0.13.1)\n",
            "Requirement already satisfied: librosa>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from tts) (0.11.0)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from tts) (1.6.1)\n",
            "Requirement already satisfied: inflect>=5.6.0 in /usr/local/lib/python3.11/dist-packages (from tts) (7.5.0)\n",
            "Requirement already satisfied: anyascii>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from tts) (0.3.2)\n",
            "Requirement already satisfied: flask>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from tts) (3.1.0)\n",
            "Requirement already satisfied: pysbd>=0.3.4 in /usr/local/lib/python3.11/dist-packages (from tts) (0.3.4)\n",
            "Requirement already satisfied: umap-learn>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tts) (0.5.7)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from tts) (3.10.0)\n",
            "Requirement already satisfied: trainer>=0.0.32 in /usr/local/lib/python3.11/dist-packages (from tts) (0.0.36)\n",
            "Requirement already satisfied: coqpit>=0.0.16 in /usr/local/lib/python3.11/dist-packages (from tts) (0.0.17)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.11/dist-packages (from tts) (0.42.1)\n",
            "Requirement already satisfied: pypinyin in /usr/local/lib/python3.11/dist-packages (from tts) (0.54.0)\n",
            "Requirement already satisfied: hangul-romanize in /usr/local/lib/python3.11/dist-packages (from tts) (0.1.0)\n",
            "Requirement already satisfied: gruut==2.2.3 in /usr/local/lib/python3.11/dist-packages (from gruut[de,es,fr]==2.2.3->tts) (2.2.3)\n",
            "Requirement already satisfied: jamo in /usr/local/lib/python3.11/dist-packages (from tts) (0.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from tts) (3.9.1)\n",
            "Requirement already satisfied: g2pkk>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tts) (0.1.2)\n",
            "Requirement already satisfied: bangla in /usr/local/lib/python3.11/dist-packages (from tts) (0.0.2)\n",
            "Requirement already satisfied: bnnumerizer in /usr/local/lib/python3.11/dist-packages (from tts) (0.0.2)\n",
            "Requirement already satisfied: bnunicodenormalizer in /usr/local/lib/python3.11/dist-packages (from tts) (0.1.7)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from tts) (0.8.1)\n",
            "Requirement already satisfied: transformers>=4.33.0 in /usr/local/lib/python3.11/dist-packages (from tts) (4.50.3)\n",
            "Requirement already satisfied: encodec>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tts) (0.1.1)\n",
            "Requirement already satisfied: unidecode>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from tts) (1.3.8)\n",
            "Requirement already satisfied: num2words in /usr/local/lib/python3.11/dist-packages (from tts) (0.5.14)\n",
            "Requirement already satisfied: spacy>=3 in /usr/local/lib/python3.11/dist-packages (from spacy[ja]>=3->tts) (3.8.5)\n",
            "Requirement already satisfied: numba>=0.57.0 in /usr/local/lib/python3.11/dist-packages (from tts) (0.60.0)\n",
            "Requirement already satisfied: Babel<3.0.0,>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->tts) (2.17.0)\n",
            "Requirement already satisfied: dateparser~=1.1.0 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->tts) (1.1.8)\n",
            "Requirement already satisfied: gruut-ipa<1.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->tts) (0.13.0)\n",
            "Requirement already satisfied: gruut-lang-en~=2.0.0 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->tts) (2.0.1)\n",
            "Requirement already satisfied: jsonlines~=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->tts) (1.2.0)\n",
            "Requirement already satisfied: networkx<3.0.0,>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->tts) (2.8.8)\n",
            "Requirement already satisfied: python-crfsuite~=0.9.7 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->tts) (0.9.11)\n",
            "Requirement already satisfied: gruut-lang-de~=2.0.0 in /usr/local/lib/python3.11/dist-packages (from gruut[de,es,fr]==2.2.3->tts) (2.0.1)\n",
            "Requirement already satisfied: gruut-lang-es~=2.0.0 in /usr/local/lib/python3.11/dist-packages (from gruut[de,es,fr]==2.2.3->tts) (2.0.1)\n",
            "Requirement already satisfied: gruut-lang-fr~=2.0.0 in /usr/local/lib/python3.11/dist-packages (from gruut[de,es,fr]==2.2.3->tts) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.3.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->tts) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->tts) (3.1.6)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->tts) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->tts) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->tts) (1.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.0)\n",
            "Requirement already satisfied: more_itertools>=8.5.0 in /usr/local/lib/python3.11/dist-packages (from inflect>=5.6.0->tts) (10.6.0)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from inflect>=5.6.0->tts) (4.4.2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->tts) (3.0.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->tts) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->tts) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->tts) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->tts) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->tts) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->tts) (1.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->tts) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->tts) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->tts) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->tts) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->tts) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->tts) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->tts) (2.8.2)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.11/dist-packages (from num2words->tts) (0.6.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.57.0->tts) (0.43.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.0->tts) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.0->tts) (1.17.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->tts) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->tts) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->tts) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->tts) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->tts) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->tts) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->tts) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->tts) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->tts) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->tts) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->tts) (0.15.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->tts) (2.11.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->tts) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->tts) (3.5.0)\n",
            "Requirement already satisfied: sudachipy!=0.6.1,>=0.5.2 in /usr/local/lib/python3.11/dist-packages (from spacy[ja]>=3->tts) (0.6.10)\n",
            "Requirement already satisfied: sudachidict_core>=20211220 in /usr/local/lib/python3.11/dist-packages (from spacy[ja]>=3->tts) (20250129)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->tts) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->tts) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->tts) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->tts) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->tts) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->tts) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->tts) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->tts) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->tts) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->tts) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->tts) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->tts) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->tts) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->tts) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->tts) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1->tts) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from trainer>=0.0.32->tts) (5.9.5)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from trainer>=0.0.32->tts) (2.18.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.33.0->tts) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.33.0->tts) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.33.0->tts) (0.5.3)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn>=0.5.1->tts) (0.5.13)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.0->tts) (2.22)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.11/dist-packages (from dateparser~=1.1.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->tts) (5.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask>=2.0.1->tts) (3.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from jsonlines~=1.2.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->tts) (1.17.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3->spacy[ja]>=3->tts) (1.3.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa>=0.10.0->tts) (4.3.7)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->tts) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->tts) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->tts) (0.4.0)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=3->spacy[ja]>=3->tts) (1.2.1)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=3->spacy[ja]>=3->tts) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->tts) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->tts) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->tts) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->tts) (7.1.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->tts) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->tts) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->tts) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->tts) (5.29.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->tts) (0.7.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3->spacy[ja]>=3->tts) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->tts) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->tts) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->tts) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->tts) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall numpy pandas -y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "\"\"\"\n",
        "Fine-tuning script for Coqui XTTS v2 on Bengali language data\n",
        "Uses Common Voice Bengali dataset for training\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import gc\n",
        "import re\n",
        "import json\n",
        "import shutil\n",
        "import random\n",
        "import logging\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from typing import List, Dict, Any, Tuple\n",
        "\n",
        "# Fix dependency issues before importing numpy and other libraries\n",
        "def setup_environment():\n",
        "    \"\"\"Set up the environment with correct dependencies.\"\"\"\n",
        "    import subprocess\n",
        "    import sys\n",
        "\n",
        "    # Install/reinstall packages with compatible versions\n",
        "    packages = [\n",
        "        \"numpy<1.24\",  # Specific version to avoid compatibility issues\n",
        "        \"pandasai\",\n",
        "        \"torch==2.0.1\",\n",
        "        \"torchaudio==2.0.2\",\n",
        "        \"librosa==0.10.1\",\n",
        "        \"datasets==2.14.5\",\n",
        "        \"scikit-learn==1.3.0\",\n",
        "        \"matplotlib==3.7.2\",\n",
        "        \"TTS==0.17.5\"      # Coqui TTS library\n",
        "    ]\n",
        "\n",
        "    print(\"Setting up environment with compatible packages...\")\n",
        "    for package in packages:\n",
        "        print(f\"Installing {package}...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "    print(\"Environment setup complete.\")\n",
        "\n",
        "# Run setup before importing problematic packages\n",
        "setup_environment()\n",
        "\n",
        "# Now import the packages after setting up the environment\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torchaudio\n",
        "import librosa\n",
        "import librosa.display\n",
        "from datasets import load_dataset, Audio\n",
        "from sklearn.model_selection import train_test_split\n",
        "from IPython.display import Audio as IPythonAudio\n",
        "\n",
        "# Import TTS after ensuring proper environment setup\n",
        "from TTS.tts.configs.xtts_config import XttsConfig\n",
        "from TTS.tts.models.xtts import Xtts\n",
        "from TTS.utils.manage import ModelManager\n",
        "from TTS.utils.audio import AudioProcessor\n",
        "from TTS.tts.datasets.dataset import TTSDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# Configuration\n",
        "class Config:\n",
        "    # General settings\n",
        "    output_dir = \"./xtts_bengali_finetuned\"\n",
        "    original_model_name = \"tts_models/multilingual/multi-dataset/xtts_v2\"\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # Dataset settings\n",
        "    dataset_name = \"mozilla-foundation/common_voice_13_0\"\n",
        "    dataset_config = \"bn\"\n",
        "    dataset_split = \"train\"\n",
        "    streaming = True\n",
        "    max_samples = 5000  # Max number of samples to use for fine-tuning\n",
        "    test_size = 0.1  # 10% of data used for testing\n",
        "    val_size = 0.1  # 10% of data used for validation\n",
        "    min_audio_length = 1.0  # Minimum audio length in seconds\n",
        "    max_audio_length = 20.0  # Maximum audio length in seconds\n",
        "    target_sample_rate = 24000  # XTTS requires 24kHz\n",
        "\n",
        "    # Data preparation settings\n",
        "    preprocessed_dir = \"./preprocessed_data\"\n",
        "    metadata_file = \"metadata.csv\"\n",
        "\n",
        "    # Training settings\n",
        "    batch_size = 4\n",
        "    eval_batch_size = 4\n",
        "    num_epochs = 10\n",
        "    learning_rate = 5e-5\n",
        "    save_checkpoints = True\n",
        "    checkpoint_dir = \"./checkpoints\"\n",
        "    checkpoint_interval = 1000  # Save checkpoint every N steps\n",
        "\n",
        "    # Evaluation settings\n",
        "    num_test_samples = 5  # Number of samples to generate for evaluation\n",
        "\n",
        "\n",
        "def download_model():\n",
        "    \"\"\"Download the pre-trained XTTS v2 model\"\"\"\n",
        "    logger.info(\"Downloading pre-trained XTTS v2 model...\")\n",
        "    manager = ModelManager()\n",
        "    model_path, config_path, _ = manager.download_model(Config.original_model_name)\n",
        "    return model_path, config_path\n",
        "\n",
        "\n",
        "def prepare_dataset():\n",
        "    \"\"\"Prepare the Bengali Common Voice dataset for fine-tuning\"\"\"\n",
        "    logger.info(\"Loading Common Voice Bengali dataset...\")\n",
        "\n",
        "    # Load the dataset\n",
        "    cv_dataset = load_dataset(\n",
        "        Config.dataset_name,\n",
        "        Config.dataset_config,\n",
        "        split=Config.dataset_split,\n",
        "        streaming=Config.streaming\n",
        "    )\n",
        "\n",
        "    # Convert to audio format\n",
        "    cv_dataset = cv_dataset.cast_column(\"audio\", Audio(sampling_rate=Config.target_sample_rate))\n",
        "\n",
        "    # Create preprocessed directory\n",
        "    os.makedirs(Config.preprocessed_dir, exist_ok=True)\n",
        "\n",
        "    logger.info(\"Preprocessing dataset...\")\n",
        "    metadata = []\n",
        "    count = 0\n",
        "\n",
        "    # Process samples\n",
        "    for sample in tqdm(cv_dataset.take(Config.max_samples)):\n",
        "        # Skip if no audio or sentence\n",
        "        if not sample[\"audio\"] or not sample[\"sentence\"]:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # Load and resample audio\n",
        "            audio_array = sample[\"audio\"][\"array\"]\n",
        "            sample_rate = sample[\"audio\"][\"sampling_rate\"]\n",
        "\n",
        "            # Check audio length\n",
        "            duration = len(audio_array) / sample_rate\n",
        "            if duration < Config.min_audio_length or duration > Config.max_audio_length:\n",
        "                continue\n",
        "\n",
        "            # Create a unique filename\n",
        "            filename = f\"sample_{count:05d}.wav\"\n",
        "            filepath = os.path.join(Config.preprocessed_dir, filename)\n",
        "\n",
        "            # Save audio file\n",
        "            if sample_rate != Config.target_sample_rate:\n",
        "                audio_array = librosa.resample(\n",
        "                    audio_array,\n",
        "                    orig_sr=sample_rate,\n",
        "                    target_sr=Config.target_sample_rate\n",
        "                )\n",
        "\n",
        "            # Convert to 16-bit PCM\n",
        "            audio_array = (audio_array * 32767).astype(np.int16)\n",
        "\n",
        "            # Save as WAV\n",
        "            torchaudio.save(\n",
        "                filepath,\n",
        "                torch.tensor(audio_array).unsqueeze(0),\n",
        "                Config.target_sample_rate,\n",
        "                bits_per_sample=16\n",
        "            )\n",
        "\n",
        "            # Add to metadata\n",
        "            metadata.append({\n",
        "                \"audio_file\": filename,\n",
        "                \"text\": sample[\"sentence\"],\n",
        "                \"duration\": duration\n",
        "            })\n",
        "\n",
        "            count += 1\n",
        "            if count % 100 == 0:\n",
        "                logger.info(f\"Processed {count} samples\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error processing sample: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    logger.info(f\"Total processed samples: {len(metadata)}\")\n",
        "\n",
        "    # Create train-val-test split\n",
        "    train_meta, test_meta = train_test_split(\n",
        "        metadata,\n",
        "        test_size=Config.test_size,\n",
        "        random_state=SEED\n",
        "    )\n",
        "    train_meta, val_meta = train_test_split(\n",
        "        train_meta,\n",
        "        test_size=Config.val_size / (1 - Config.test_size),\n",
        "        random_state=SEED\n",
        "    )\n",
        "\n",
        "    logger.info(f\"Train samples: {len(train_meta)}\")\n",
        "    logger.info(f\"Validation samples: {len(val_meta)}\")\n",
        "    logger.info(f\"Test samples: {len(test_meta)}\")\n",
        "\n",
        "    # Save metadata\n",
        "    os.makedirs(os.path.join(Config.preprocessed_dir, \"train\"), exist_ok=True)\n",
        "    os.makedirs(os.path.join(Config.preprocessed_dir, \"val\"), exist_ok=True)\n",
        "    os.makedirs(os.path.join(Config.preprocessed_dir, \"test\"), exist_ok=True)\n",
        "\n",
        "    # Create metadata files\n",
        "    for split_name, split_data in [(\"train\", train_meta), (\"val\", val_meta), (\"test\", test_meta)]:\n",
        "        split_df = pd.DataFrame(split_data)\n",
        "\n",
        "        # Copy files to split directories\n",
        "        for idx, row in split_df.iterrows():\n",
        "            src_path = os.path.join(Config.preprocessed_dir, row[\"audio_file\"])\n",
        "            dst_path = os.path.join(Config.preprocessed_dir, split_name, row[\"audio_file\"])\n",
        "            shutil.copy(src_path, dst_path)\n",
        "\n",
        "        # Save metadata\n",
        "        metadata_path = os.path.join(Config.preprocessed_dir, f\"{split_name}_{Config.metadata_file}\")\n",
        "        split_df[\"audio_file\"] = split_df[\"audio_file\"].apply(\n",
        "            lambda x: os.path.join(split_name, x)\n",
        "        )\n",
        "        split_df.to_csv(metadata_path, index=False)\n",
        "\n",
        "    # Remove original files\n",
        "    for file in os.listdir(Config.preprocessed_dir):\n",
        "        if file.endswith(\".wav\"):\n",
        "            os.remove(os.path.join(Config.preprocessed_dir, file))\n",
        "\n",
        "    return os.path.join(Config.preprocessed_dir, f\"train_{Config.metadata_file}\"), \\\n",
        "           os.path.join(Config.preprocessed_dir, f\"val_{Config.metadata_file}\"), \\\n",
        "           os.path.join(Config.preprocessed_dir, f\"test_{Config.metadata_file}\")\n",
        "\n",
        "\n",
        "def modify_config(config_path, train_meta_path, val_meta_path):\n",
        "    \"\"\"Modify the XTTS config for fine-tuning\"\"\"\n",
        "    logger.info(\"Modifying XTTS config for fine-tuning...\")\n",
        "\n",
        "    # Load the original config\n",
        "    config = XttsConfig()\n",
        "    config.load_json(config_path)\n",
        "\n",
        "    # Modify config for fine-tuning\n",
        "    config.audio.resample = True\n",
        "    config.audio.sample_rate = Config.target_sample_rate\n",
        "\n",
        "    # Dataset config\n",
        "    config.datasets = [\n",
        "        {\n",
        "            \"name\": \"bengali_cv\",\n",
        "            \"path\": Config.preprocessed_dir,\n",
        "            \"meta_file_train\": train_meta_path,\n",
        "            \"meta_file_val\": val_meta_path,\n",
        "            \"language\": \"bn\"  # Bengali language code\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Training config\n",
        "    config.trainer_params.max_epochs = Config.num_epochs\n",
        "    config.trainer_params.batch_size = Config.batch_size\n",
        "    config.trainer_params.eval_batch_size = Config.eval_batch_size\n",
        "    config.trainer_params.gradient_clip = 1.0\n",
        "    config.trainer_params.scheduler_after_epoch = True\n",
        "\n",
        "    # Optimizer config\n",
        "    config.optimizer_params.lr = Config.learning_rate\n",
        "    config.optimizer_params.weight_decay = 0.01\n",
        "\n",
        "    # Create output directory\n",
        "    os.makedirs(Config.output_dir, exist_ok=True)\n",
        "\n",
        "    # Save modified config\n",
        "    modified_config_path = os.path.join(Config.output_dir, \"config.json\")\n",
        "    config.save_json(modified_config_path)\n",
        "\n",
        "    return modified_config_path, config\n",
        "\n",
        "\n",
        "def fine_tune_model(model_path, config_path, config_obj):\n",
        "    \"\"\"Fine-tune the XTTS model on Bengali data\"\"\"\n",
        "    logger.info(\"Starting fine-tuning...\")\n",
        "\n",
        "    # Create checkpoint directory\n",
        "    os.makedirs(Config.checkpoint_dir, exist_ok=True)\n",
        "\n",
        "    # Initialize model\n",
        "    model = Xtts.init_from_config(config_obj)\n",
        "    model.load_checkpoint(config_obj, checkpoint_path=model_path, eval=False)\n",
        "    model.to(Config.device)\n",
        "\n",
        "    # Set up optimizer\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr=Config.learning_rate,\n",
        "        weight_decay=0.01\n",
        "    )\n",
        "\n",
        "    # Train loop\n",
        "    try:\n",
        "        model.train()\n",
        "        for epoch in range(Config.num_epochs):\n",
        "            logger.info(f\"Starting epoch {epoch+1}/{Config.num_epochs}\")\n",
        "\n",
        "            # Create dataset and dataloader for this epoch\n",
        "            train_dataset = TTSDataset.init_from_config(config_obj, \"train\")\n",
        "            train_loader = DataLoader(\n",
        "                train_dataset,\n",
        "                batch_size=Config.batch_size,\n",
        "                shuffle=True,\n",
        "                num_workers=4,\n",
        "                collate_fn=train_dataset.collate_fn\n",
        "            )\n",
        "\n",
        "            epoch_loss = 0\n",
        "            num_batches = 0\n",
        "\n",
        "            for batch_idx, batch in enumerate(tqdm(train_loader)):\n",
        "                # Move batch to device\n",
        "                for k, v in batch.items():\n",
        "                    if isinstance(v, torch.Tensor):\n",
        "                        batch[k] = v.to(Config.device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model.train_step(batch)\n",
        "                loss = outputs[\"loss\"]\n",
        "\n",
        "                # Backward pass\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                optimizer.step()\n",
        "\n",
        "                # Update metrics\n",
        "                epoch_loss += loss.item()\n",
        "                num_batches += 1\n",
        "\n",
        "                # Save checkpoint\n",
        "                if batch_idx % Config.checkpoint_interval == 0 and batch_idx > 0:\n",
        "                    checkpoint_path = os.path.join(\n",
        "                        Config.checkpoint_dir,\n",
        "                        f\"checkpoint_epoch{epoch+1}_batch{batch_idx}.pth\"\n",
        "                    )\n",
        "                    model.save_checkpoint(config_obj, checkpoint_path)\n",
        "                    logger.info(f\"Checkpoint saved at {checkpoint_path}\")\n",
        "\n",
        "            # Calculate average loss for the epoch\n",
        "            avg_loss = epoch_loss / num_batches\n",
        "            logger.info(f\"Epoch {epoch+1} - Average loss: {avg_loss:.4f}\")\n",
        "\n",
        "            # Save epoch checkpoint\n",
        "            checkpoint_path = os.path.join(\n",
        "                Config.checkpoint_dir,\n",
        "                f\"checkpoint_epoch{epoch+1}.pth\"\n",
        "            )\n",
        "            model.save_checkpoint(config_obj, checkpoint_path)\n",
        "            logger.info(f\"Epoch checkpoint saved at {checkpoint_path}\")\n",
        "\n",
        "            # Evaluate on validation set\n",
        "            model.eval()\n",
        "            val_dataset = TTSDataset.init_from_config(config_obj, \"val\")\n",
        "            val_loader = DataLoader(\n",
        "                val_dataset,\n",
        "                batch_size=Config.eval_batch_size,\n",
        "                shuffle=False,\n",
        "                num_workers=4,\n",
        "                collate_fn=val_dataset.collate_fn\n",
        "            )\n",
        "\n",
        "            val_loss = 0\n",
        "            val_batches = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for val_batch in tqdm(val_loader):\n",
        "                    # Move batch to device\n",
        "                    for k, v in val_batch.items():\n",
        "                        if isinstance(v, torch.Tensor):\n",
        "                            val_batch[k] = v.to(Config.device)\n",
        "\n",
        "                    # Forward pass\n",
        "                    val_outputs = model.train_step(val_batch)\n",
        "                    val_loss += val_outputs[\"loss\"].item()\n",
        "                    val_batches += 1\n",
        "\n",
        "            avg_val_loss = val_loss / val_batches\n",
        "            logger.info(f\"Validation loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "            # Set back to training mode\n",
        "            model.train()\n",
        "\n",
        "            # Clear memory\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        # Save final model\n",
        "        final_model_path = os.path.join(Config.output_dir, \"model.pth\")\n",
        "        model.save_checkpoint(config_obj, final_model_path)\n",
        "        logger.info(f\"Final model saved at {final_model_path}\")\n",
        "\n",
        "        return final_model_path\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error during fine-tuning: {str(e)}\")\n",
        "        # Try to save checkpoint on error\n",
        "        error_checkpoint_path = os.path.join(Config.checkpoint_dir, \"error_checkpoint.pth\")\n",
        "        model.save_checkpoint(config_obj, error_checkpoint_path)\n",
        "        logger.info(f\"Emergency checkpoint saved at {error_checkpoint_path}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "def evaluate_model(model_path, config_path, test_meta_path):\n",
        "    \"\"\"Evaluate the fine-tuned model on test samples\"\"\"\n",
        "    logger.info(\"Evaluating fine-tuned model...\")\n",
        "\n",
        "    # Load config and model\n",
        "    config = XttsConfig()\n",
        "    config.load_json(config_path)\n",
        "\n",
        "    # Initialize model\n",
        "    model = Xtts.init_from_config(config)\n",
        "    model.load_checkpoint(config, checkpoint_path=model_path, eval=True)\n",
        "    model.to(Config.device)\n",
        "\n",
        "    # Load test metadata\n",
        "    test_df = pd.read_csv(test_meta_path)\n",
        "    test_samples = test_df.sample(min(Config.num_test_samples, len(test_df))).to_dict('records')\n",
        "\n",
        "    # Load original model for comparison\n",
        "    logger.info(\"Loading original model for comparison...\")\n",
        "    original_model_path, original_config_path, _ = ModelManager().download_model(Config.original_model_name)\n",
        "    original_config = XttsConfig()\n",
        "    original_config.load_json(original_config_path)\n",
        "    original_model = Xtts.init_from_config(original_config)\n",
        "    original_model.load_checkpoint(original_config, checkpoint_path=original_model_path, eval=True)\n",
        "    original_model.to(Config.device)\n",
        "\n",
        "    # Create evaluation directory\n",
        "    eval_dir = os.path.join(Config.output_dir, \"evaluation\")\n",
        "    os.makedirs(eval_dir, exist_ok=True)\n",
        "\n",
        "    # Set up evaluation metrics\n",
        "    metrics = {\n",
        "        \"original\": {\n",
        "            \"spectrograms\": [],\n",
        "            \"audios\": [],\n",
        "            \"mcd\": []  # Mel Cepstral Distortion\n",
        "        },\n",
        "        \"finetuned\": {\n",
        "            \"spectrograms\": [],\n",
        "            \"audios\": [],\n",
        "            \"mcd\": []\n",
        "        },\n",
        "        \"reference\": {\n",
        "            \"spectrograms\": [],\n",
        "            \"audios\": []\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Process test samples\n",
        "    for i, sample in enumerate(test_samples):\n",
        "        logger.info(f\"Processing test sample {i+1}/{len(test_samples)}\")\n",
        "\n",
        "        # Load reference audio\n",
        "        ref_path = os.path.join(Config.preprocessed_dir, sample[\"audio_file\"])\n",
        "        ref_audio, sr = librosa.load(ref_path, sr=Config.target_sample_rate)\n",
        "        ref_file_path = os.path.join(eval_dir, f\"reference_{i}.wav\")\n",
        "\n",
        "        # Write reference audio (using scipy instead of deprecated librosa.output)\n",
        "        from scipy.io import wavfile\n",
        "        wavfile.write(ref_file_path, sr, (ref_audio * 32767).astype(np.int16))\n",
        "\n",
        "        # Get reference spectrogram\n",
        "        ref_mel = librosa.feature.melspectrogram(\n",
        "            y=ref_audio,\n",
        "            sr=sr,\n",
        "            n_mels=80,\n",
        "            fmin=0,\n",
        "            fmax=8000\n",
        "        )\n",
        "        ref_mel_db = librosa.power_to_db(ref_mel, ref=np.max)\n",
        "\n",
        "        # Store reference data\n",
        "        metrics[\"reference\"][\"spectrograms\"].append(ref_mel_db)\n",
        "        metrics[\"reference\"][\"audios\"].append(ref_audio)\n",
        "\n",
        "        # Generate with original model\n",
        "        speaker_wav = ref_path\n",
        "        text = sample[\"text\"]\n",
        "\n",
        "        try:\n",
        "            # Original model synthesis\n",
        "            with torch.no_grad():\n",
        "                original_output = original_model.synthesize(\n",
        "                    text,\n",
        "                    speaker_wav,\n",
        "                    language=\"bn\",\n",
        "                    gpt_cond_len=3,\n",
        "                    speed=1.0\n",
        "                )\n",
        "\n",
        "            original_audio = original_output[\"wav\"].squeeze().cpu().numpy()\n",
        "            original_file_path = os.path.join(eval_dir, f\"original_{i}.wav\")\n",
        "\n",
        "            # Write original audio\n",
        "            wavfile.write(original_file_path, Config.target_sample_rate,\n",
        "                         (original_audio * 32767).astype(np.int16))\n",
        "\n",
        "            # Get original spectrogram\n",
        "            original_mel = librosa.feature.melspectrogram(\n",
        "                y=original_audio,\n",
        "                sr=Config.target_sample_rate,\n",
        "                n_mels=80,\n",
        "                fmin=0,\n",
        "                fmax=8000\n",
        "            )\n",
        "            original_mel_db = librosa.power_to_db(original_mel, ref=np.max)\n",
        "\n",
        "            # Calculate MCD for original vs reference\n",
        "            original_mcd = calculate_mcd(ref_mel, original_mel)\n",
        "\n",
        "            # Store original data\n",
        "            metrics[\"original\"][\"spectrograms\"].append(original_mel_db)\n",
        "            metrics[\"original\"][\"audios\"].append(original_audio)\n",
        "            metrics[\"original\"][\"mcd\"].append(original_mcd)\n",
        "\n",
        "            # Fine-tuned model synthesis\n",
        "            with torch.no_grad():\n",
        "                finetuned_output = model.synthesize(\n",
        "                    text,\n",
        "                    speaker_wav,\n",
        "                    language=\"bn\",\n",
        "                    gpt_cond_len=3,\n",
        "                    speed=1.0\n",
        "                )\n",
        "\n",
        "            finetuned_audio = finetuned_output[\"wav\"].squeeze().cpu().numpy()\n",
        "            finetuned_file_path = os.path.join(eval_dir, f\"finetuned_{i}.wav\")\n",
        "\n",
        "            # Write fine-tuned audio\n",
        "            wavfile.write(finetuned_file_path, Config.target_sample_rate,\n",
        "                         (finetuned_audio * 32767).astype(np.int16))\n",
        "\n",
        "            # Get fine-tuned spectrogram\n",
        "            finetuned_mel = librosa.feature.melspectrogram(\n",
        "                y=finetuned_audio,\n",
        "                sr=Config.target_sample_rate,\n",
        "                n_mels=80,\n",
        "                fmin=0,\n",
        "                fmax=8000\n",
        "            )\n",
        "            finetuned_mel_db = librosa.power_to_db(finetuned_mel, ref=np.max)\n",
        "\n",
        "            # Calculate MCD for fine-tuned vs reference\n",
        "            finetuned_mcd = calculate_mcd(ref_mel, finetuned_mel)\n",
        "\n",
        "            # Store fine-tuned data\n",
        "            metrics[\"finetuned\"][\"spectrograms\"].append(finetuned_mel_db)\n",
        "            metrics[\"finetuned\"][\"audios\"].append(finetuned_audio)\n",
        "            metrics[\"finetuned\"][\"mcd\"].append(finetuned_mcd)\n",
        "\n",
        "            # Save sample info\n",
        "            with open(os.path.join(eval_dir, f\"sample_{i}_info.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "                json.dump({\n",
        "                    \"text\": text,\n",
        "                    \"original_mcd\": float(original_mcd),\n",
        "                    \"finetuned_mcd\": float(finetuned_mcd),\n",
        "                    \"reference_path\": ref_file_path,\n",
        "                    \"original_path\": original_file_path,\n",
        "                    \"finetuned_path\": finetuned_file_path\n",
        "                }, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error generating sample {i}: {str(e)}\")\n",
        "\n",
        "    # Generate comparison plots\n",
        "    generate_comparison_plots(metrics, eval_dir)\n",
        "\n",
        "    # Calculate average MCD scores\n",
        "    avg_original_mcd = np.mean(metrics[\"original\"][\"mcd\"])\n",
        "    avg_finetuned_mcd = np.mean(metrics[\"finetuned\"][\"mcd\"])\n",
        "\n",
        "    logger.info(f\"Average MCD for original model: {avg_original_mcd:.4f}\")\n",
        "    logger.info(f\"Average MCD for fine-tuned model: {avg_finetuned_mcd:.4f}\")\n",
        "    logger.info(f\"MCD improvement: {avg_original_mcd - avg_finetuned_mcd:.4f}\")\n",
        "\n",
        "    # Save evaluation summary\n",
        "    summary = {\n",
        "        \"avg_original_mcd\": float(avg_original_mcd),\n",
        "        \"avg_finetuned_mcd\": float(avg_finetuned_mcd),\n",
        "        \"mcd_improvement\": float(avg_original_mcd - avg_finetuned_mcd),\n",
        "        \"num_samples\": len(test_samples)\n",
        "    }\n",
        "\n",
        "    with open(os.path.join(eval_dir, \"evaluation_summary.json\"), \"w\") as f:\n",
        "        json.dump(summary, f, indent=2)\n",
        "\n",
        "    return summary\n",
        "\n",
        "\n",
        "def calculate_mcd(ref_mel, test_mel):\n",
        "    \"\"\"Calculate Mel Cepstral Distortion between two mel spectrograms\"\"\"\n",
        "    # Convert to MFCCs (Mel Frequency Cepstral Coefficients)\n",
        "    ref_mfcc = librosa.feature.mfcc(S=librosa.power_to_db(ref_mel), n_mfcc=13)\n",
        "    test_mfcc = librosa.feature.mfcc(S=librosa.power_to_db(test_mel), n_mfcc=13)\n",
        "\n",
        "    # Make sure they have the same length\n",
        "    min_len = min(ref_mfcc.shape[1], test_mfcc.shape[1])\n",
        "    ref_mfcc = ref_mfcc[:, :min_len]\n",
        "    test_mfcc = test_mfcc[:, :min_len]\n",
        "\n",
        "    # Calculate Euclidean distance\n",
        "    diff = ref_mfcc - test_mfcc\n",
        "    mcd = np.sqrt(np.sum(diff**2, axis=0)).mean()\n",
        "\n",
        "    return mcd\n",
        "\n",
        "\n",
        "def generate_comparison_plots(metrics, eval_dir):\n",
        "    \"\"\"Generate comparison plots between original and fine-tuned models\"\"\"\n",
        "    logger.info(\"Generating comparison plots...\")\n",
        "\n",
        "    # Create plots directory\n",
        "    plots_dir = os.path.join(eval_dir, \"plots\")\n",
        "    os.makedirs(plots_dir, exist_ok=True)\n",
        "\n",
        "    # Generate spectrogram comparisons\n",
        "    for i in range(len(metrics[\"reference\"][\"spectrograms\"])):\n",
        "        plt.figure(figsize=(15, 10))\n",
        "\n",
        "        plt.subplot(3, 1, 1)\n",
        "        librosa.display.specshow(\n",
        "            metrics[\"reference\"][\"spectrograms\"][i],\n",
        "            sr=Config.target_sample_rate,\n",
        "            x_axis='time',\n",
        "            y_axis='mel',\n",
        "            fmax=8000\n",
        "        )\n",
        "        plt.colorbar(format='%+2.0f dB')\n",
        "        plt.title('Reference Audio Spectrogram')\n",
        "\n",
        "        plt.subplot(3, 1, 2)\n",
        "        librosa.display.specshow(\n",
        "            metrics[\"original\"][\"spectrograms\"][i],\n",
        "            sr=Config.target_sample_rate,\n",
        "            x_axis='time',\n",
        "            y_axis='mel',\n",
        "            fmax=8000\n",
        "        )\n",
        "        plt.colorbar(format='%+2.0f dB')\n",
        "        plt.title(f'Original Model Spectrogram (MCD: {metrics[\"original\"][\"mcd\"][i]:.4f})')\n",
        "\n",
        "        plt.subplot(3, 1, 3)\n",
        "        librosa.display.specshow(\n",
        "            metrics[\"finetuned\"][\"spectrograms\"][i],\n",
        "            sr=Config.target_sample_rate,\n",
        "            x_axis='time',\n",
        "            y_axis='mel',\n",
        "            fmax=8000\n",
        "        )\n",
        "        plt.colorbar(format='%+2.0f dB')\n",
        "        plt.title(f'Fine-tuned Model Spectrogram (MCD: {metrics[\"finetuned\"][\"mcd\"][i]:.4f})')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(plots_dir, f\"spectrogram_comparison_{i}.png\"))\n",
        "        plt.close()\n",
        "\n",
        "    # Generate MCD comparison plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    x = np.arange(len(metrics[\"original\"][\"mcd\"]))\n",
        "    width = 0.35\n",
        "\n",
        "    plt.bar(x - width/2, metrics[\"original\"][\"mcd\"], width, label='Original Model')\n",
        "    plt.bar(x + width/2, metrics[\"finetuned\"][\"mcd\"], width, label='Fine-tuned Model')\n",
        "\n",
        "    plt.xlabel('Sample Index')\n",
        "    plt.ylabel('MCD (lower is better)')\n",
        "    plt.title('Mel Cepstral Distortion Comparison')\n",
        "    plt.xticks(x)\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(plots_dir, \"mcd_comparison.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Generate average MCD comparison\n",
        "    avg_original_mcd = np.mean(metrics[\"original\"][\"mcd\"])\n",
        "    avg_finetuned_mcd = np.mean(metrics[\"finetuned\"][\"mcd\"])\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "\n",
        "    plt.bar([\"Original Model\", \"Fine-tuned Model\"],\n",
        "            [avg_original_mcd, avg_finetuned_mcd])\n",
        "\n",
        "    plt.ylabel('Average MCD (lower is better)')\n",
        "    plt.title('Average Mel Cepstral Distortion')\n",
        "\n",
        "    for i, v in enumerate([avg_original_mcd, avg_finetuned_mcd]):\n",
        "        plt.text(i, v + 0.1, f\"{v:.4f}\", ha='center')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(plots_dir, \"avg_mcd_comparison.png\"))\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run the fine-tuning workflow\"\"\"\n",
        "    try:\n",
        "        # Setup\n",
        "        logger.info(\"Starting XTTS v2 fine-tuning for Bengali\")\n",
        "        logger.info(f\"Using device: {Config.device}\")\n",
        "\n",
        "        # Download model\n",
        "        model_path, config_path = download_model()\n",
        "        logger.info(f\"Original model downloaded to {model_path}\")\n",
        "\n",
        "        # Prepare dataset\n",
        "        train_meta_path, val_meta_path, test_meta_path = prepare_dataset()\n",
        "        logger.info(f\"Dataset prepared and split: {Config.preprocessed_dir}\")\n",
        "\n",
        "        # Modify config\n",
        "        modified_config_path, config_obj = modify_config(config_path, train_meta_path, val_meta_path)\n",
        "        logger.info(f\"Modified config saved to {modified_config_path}\")\n",
        "\n",
        "        # Fine-tune model\n",
        "        finetuned_model_path = fine_tune_model(model_path, modified_config_path, config_obj)\n",
        "        logger.info(f\"Fine-tuning completed. Model saved to {finetuned_model_path}\")\n",
        "\n",
        "        # Evaluate model\n",
        "        evaluation_results = evaluate_model(finetuned_model_path, modified_config_path, test_meta_path)\n",
        "        logger.info(\"Evaluation completed.\")\n",
        "\n",
        "        # Final report\n",
        "        if evaluation_results[\"mcd_improvement\"] > 0:\n",
        "            logger.info(\"🎉 Fine-tuning was successful! The model shows improvement on Bengali data.\")\n",
        "        else:\n",
        "            logger.info(\"⚠️ The fine-tuned model did not show improvement according to MCD metrics.\")\n",
        "\n",
        "        logger.info(f\"All outputs saved to {Config.output_dir}\")\n",
        "        logger.info(\"Process completed successfully.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in main process: {str(e)}\")\n",
        "        import traceback\n",
        "        logger.error(traceback.format_exc())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddntuwtBMR3j",
        "outputId": "4a207367-be36-4ccc-cea2-656e605603b6"
      },
      "id": "ddntuwtBMR3j",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up environment with compatible packages...\n",
            "Installing numpy==1.24.3...\n",
            "Installing pandas==2.0.3...\n",
            "Installing torch==2.0.1...\n",
            "Installing torchaudio==2.0.2...\n",
            "Installing librosa==0.10.1...\n",
            "Installing datasets==2.14.5...\n",
            "Installing scikit-learn==1.3.0...\n",
            "Installing matplotlib==3.7.2...\n",
            "Installing TTS==0.17.5...\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}